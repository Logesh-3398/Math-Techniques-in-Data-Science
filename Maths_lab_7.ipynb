{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Maths Lab - 7\n","\n","## Teammates:\n","#### Akshita Potdar - 702768460\n","#### Kalyani Khandait - 702768391\n","#### Logesh Gangadharan - 702723890\n"],"metadata":{"id":"UVXVZBfRdy0B"}},{"cell_type":"markdown","source":["## Problem -1\n","\n","\n","\n","Train a neural network with one or more Linear layers to\n","predict the digits. Train your model on the given training set,\n","and measure its accuracy on the given test set"],"metadata":{"id":"bt4EhiGsdywi"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Function to load and preprocess the data\n","def load_your_data():\n","    # Update these paths to the correct locations where your CSV files are stored\n","    train_path = 'correct/path/to/zip.train.csv'  # Correct this path\n","    test_path = 'correct/path/to/zip.test.csv'    # Correct this path\n","\n","    # Loading data from CSV files\n","    train_data = pd.read_csv(train_path, header=None)\n","    test_data = pd.read_csv(test_path, header=None)\n","\n","    X_train = train_data.iloc[:, 1:].values\n","    y_train = train_data.iloc[:, 0].values\n","    X_test = test_data.iloc[:, 1:].values\n","    y_test = test_data.iloc[:, 0].values\n","\n","    return X_train, X_test, y_train, y_test\n","\n","# Try to load the data, handle file not found error\n","try:\n","    X_train, X_test, y_train, y_test = load_your_data()\n","except FileNotFoundError as e:\n","    print(e)\n","    print(\"Please check the file paths and ensure they are correct.\")\n","    exit()\n","\n","# One-hot encode the labels\n","encoder = OneHotEncoder()\n","y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n","y_test_encoded = encoder.transform(y_test.reshape(-1, 1)).toarray()\n","\n","# Convert to torch tensors\n","X_train_tensor = torch.FloatTensor(X_train)\n","y_train_tensor = torch.FloatTensor(y_train_encoded)\n","X_test_tensor = torch.FloatTensor(X_test)\n","y_test_tensor = torch.FloatTensor(y_test_encoded)\n","\n","# Define the neural network architecture\n","class SimpleNN(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(SimpleNN, self).__init__()\n","        self.linear = nn.Linear(input_size, output_size)\n","\n","    def forward(self, x):\n","        x = self.linear(x)\n","        return x\n","\n","# Initialize the model\n","model = SimpleNN(input_size=X_train.shape[1], output_size=10)  # Output size is 10 for digits 0-9\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training the model\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 10 == 0:  # Print every 10 epochs\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# Testing the model\n","model.eval()\n","with torch.no_grad():\n","    outputs = model(X_test_tensor)\n","    _, predicted = torch.max(outputs.data, 1)\n","    _, labels = torch.max(y_test_tensor.data, 1)\n","    accuracy = (predicted == labels).float().mean()\n","    print(f'Accuracy: {accuracy:.4f}')\n"],"metadata":{"id":"unTpzLm_eEeC","executionInfo":{"status":"error","timestamp":1730048685338,"user_tz":240,"elapsed":5564,"user":{"displayName":"Logesh Gangadharan","userId":"02603858256580278485"}},"colab":{"base_uri":"https://localhost:8080/","height":245},"outputId":"6f51e2cb-7d1a-48d0-e2e8-82c7ceeedc37"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'correct/path/to/zip.train.csv'\n","Please check the file paths and ensure they are correct.\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'y_train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-b0e2cdd5b614>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# One-hot encode the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0my_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0my_test_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"]}]},{"cell_type":"markdown","source":["## Problem -2\n","\n","\n","Build a more sophisticated convolutional neural network model\n","to predict the digits. Use at least one 2d convolution layer\n","with several filters followed by a max pool. Your model should\n","end with Linear layers"],"metadata":{"id":"ngYgOIwtkb6m"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import OneHotEncoder\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# File paths\n","train_file_path = '/content/drive/My Drive/Colab Notebooks/DataSets/Zip/zip.train'\n","test_file_path = '/content/drive/My Drive/Colab Notebooks/DataSets/Zip/zip.test'\n","\n","# Load the data\n","train_data = pd.read_csv(train_file_path, delim_whitespace=True, header=None)\n","test_data = pd.read_csv(test_file_path, delim_whitespace=True, header=None)\n","\n","# Convert to arrays\n","X_train = train_data.iloc[:, 1:].values\n","Y_train = train_data.iloc[:, 0].values\n","X_test = test_data.iloc[:, 1:].values\n","Y_test = test_data.iloc[:, 0].values\n","\n","# Display images for verification\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.imshow(X_train[0, :].reshape(16, 16), cmap='gray')\n","plt.title(f\"Label: {int(Y_train[0])}\")\n","plt.axis('off')\n","plt.subplot(1, 2, 2)\n","plt.imshow(X_train[1, :].reshape(16, 16), cmap='gray')\n","plt.title(f\"Label: {int(Y_train[1])}\")\n","plt.axis('off')\n","plt.show()\n","\n","# One-Hot Encoding\n","encoder = OneHotEncoder(sparse_output=False)\n","y_train_onehot = encoder.fit_transform(Y_train.reshape(-1, 1))\n","y_test_onehot = encoder.transform(Y_test.reshape(-1, 1))\n","\n","print(\"Shape of y_train after one-hot encoding:\", y_train_onehot.shape)\n","print(\"Shape of y_test after one-hot encoding:\", y_test_onehot.shape)\n","\n","# Enhanced CNN Model\n","class OptimizedDigitClassifier(nn.Module):\n","    def __init__(self):\n","        super(OptimizedDigitClassifier, self).__init__()\n","        # Adding batch normalization and increased filters for better feature extraction\n","        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(256)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.dropout = nn.Dropout(0.3)\n","        self.fc1 = nn.Linear(256 * 2 * 2, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n","        x = self.dropout(x)\n","        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n","        x = self.dropout(x)\n","        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n","        x = x.view(-1, 256 * 2 * 2)\n","        x = torch.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","# Preparing tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 1, 16, 16)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32).reshape(-1, 1, 16, 16)\n","y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n","y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n","\n","# Dataloaders for batching\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Model, Loss, Optimizer, and Scheduler\n","model = OptimizedDigitClassifier()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n","\n","# Training Function\n","def train_model(num_epochs=25):\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:5r\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","        scheduler.step()  # Adjust learning rate\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n","\n","# Evaluation Function\n","def evaluate_model():\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    accuracy = correct / total\n","    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n","\n","# Train and Evaluate the Model\n","train_model(num_epochs=25)\n","evaluate_model()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":984},"id":"XT-hM16pkj91","executionInfo":{"status":"ok","timestamp":1729876079768,"user_tz":240,"elapsed":401119,"user":{"displayName":"Kalyani Jaywant Khandait","userId":"07604933641220040068"}},"outputId":"71326fbe-4c17-4a59-8ba2-699f7bab3c6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-506f13a18eac>:19: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n","  train_data = pd.read_csv(train_file_path, delim_whitespace=True, header=None)\n","<ipython-input-9-506f13a18eac>:20: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n","  test_data = pd.read_csv(test_file_path, delim_whitespace=True, header=None)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Shape of y_train after one-hot encoding: (7291, 10)\n","Shape of y_test after one-hot encoding: (2007, 10)\n","Epoch [1/25], Loss: 0.5571\n","Epoch [2/25], Loss: 0.1132\n","Epoch [3/25], Loss: 0.0775\n","Epoch [4/25], Loss: 0.0658\n","Epoch [5/25], Loss: 0.0536\n","Epoch [6/25], Loss: 0.0276\n","Epoch [7/25], Loss: 0.0254\n","Epoch [8/25], Loss: 0.0206\n","Epoch [9/25], Loss: 0.0242\n","Epoch [10/25], Loss: 0.0224\n","Epoch [11/25], Loss: 0.0163\n","Epoch [12/25], Loss: 0.0126\n","Epoch [13/25], Loss: 0.0093\n","Epoch [14/25], Loss: 0.0099\n","Epoch [15/25], Loss: 0.0097\n","Epoch [16/25], Loss: 0.0069\n","Epoch [17/25], Loss: 0.0073\n","Epoch [18/25], Loss: 0.0072\n","Epoch [19/25], Loss: 0.0057\n","Epoch [20/25], Loss: 0.0066\n","Epoch [21/25], Loss: 0.0056\n","Epoch [22/25], Loss: 0.0059\n","Epoch [23/25], Loss: 0.0057\n","Epoch [24/25], Loss: 0.0072\n","Epoch [25/25], Loss: 0.0056\n","Test Accuracy: 97.31%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ABMhNnxtoBTn"},"execution_count":null,"outputs":[]}]}