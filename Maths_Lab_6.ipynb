{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Maths Lab - 6\n","\n","## Teammates:\n","#### Akshita Potdar - 702768460\n","#### Kalyani Khandait - 702768391\n","#### Logesh Gangadharan - 702723890\n"],"metadata":{"id":"b36HbV00AXpu"}},{"cell_type":"markdown","source":["##  Problem -1\n","\n","Use PyTorch to find a local minimum of the function\n","f (x, y) = 1 − x − y + x2 + 2y2."],"metadata":{"id":"r2CGQv0nAdR4"}},{"cell_type":"code","source":["import torch\n","\n","# Defining  the function\n","def f(x):\n","    return 1 - x[0] - x[1] + x[0]**2 + 2*x[1]**2\n","\n","# Initialize x and y with requires_grad=True to track gradients\n","x = torch.tensor([1.0, 1.0], requires_grad=True)  # Start at (1, 1)\n","\n","# Use the Adam optimizer  (lr = learning rate)\n","optimizer = torch.optim.Adam([x], lr=0.01)\n","\n","\n","maxit = 2000 # Maximum number of optimization steps\n","i = 0 # Iteration counter\n","grad = 1e6 # Keeps track of derivative with respect to x\n","\n","\n","# Optimization loop\n","while i < maxit and abs(grad) > 1e-3:\n","    i+=1\n","    optimizer.zero_grad()  # Clear the gradients\n","\n","    y = f(x)  # Calculate the function value\n","    y.backward()  # Compute the  gradients\n","    optimizer.step()     # update the parameters (here: value of x)\n","    grad_norm = x.grad.norm().item()\n","\n","    # Print the current state\n","    # print(f\"Iter: {i+1}, x = [{x[0].item():.6f}, {x[1].item():.6f}], f(x) = {y.item():.6f}, grad_norm = {grad_norm:.6f}\")\n","\n","# Final output\n","print(f\"Final x = [{x[0].item():.6f}, {x[1].item():.6f}]\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LIV2UmzuAmXn","executionInfo":{"status":"ok","timestamp":1729860393212,"user_tz":240,"elapsed":27583,"user":{"displayName":"Kalyani Jaywant Khandait","userId":"07604933641220040068"}},"outputId":"e5dae824-e220-4022-d4aa-181d0e1ed094"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Final x = [0.500000, 0.250000]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FiYSa5tBNb-A","executionInfo":{"status":"ok","timestamp":1729860393215,"user_tz":240,"elapsed":23,"user":{"displayName":"Kalyani Jaywant Khandait","userId":"07604933641220040068"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["##  Problem -2\n","\n","In this problem, you will train a neural network to predict the label\n","of the flowers in the Iris dataset that we worked with before"],"metadata":{"id":"AVmD6wkSAeiG"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"fBqUbriUAV-a","executionInfo":{"status":"ok","timestamp":1729860396538,"user_tz":240,"elapsed":3340,"user":{"displayName":"Kalyani Jaywant Khandait","userId":"07604933641220040068"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","\n","# Load the Iris dataset\n","iris = load_iris()\n","X = iris.data\n","y = iris.target.reshape(-1, 1)\n","\n","# Scale features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Convert labels using one-hot encoding\n","encoder = OneHotEncoder(sparse_output=False)  # Ensures that the output is dense\n","y_encoded = encoder.fit_transform(y)  # Output is dense by default, no need to convert to array\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n","\n","# Convert data to torch tensors\n","X_train_tensor = torch.FloatTensor(X_train)\n","y_train_tensor = torch.FloatTensor(y_train)\n","X_test_tensor = torch.FloatTensor(X_test)\n","y_test_tensor = torch.FloatTensor(y_test)\n"]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class SimpleNN(nn.Module):\n","    def __init__(self, input_features, hidden_units, output_features):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(input_features, hidden_units)  # Input to hidden layer\n","        self.relu = nn.ReLU()                                          # ReLU activation\n","        self.fc2 = nn.Linear(hidden_units, output_features)  # Hidden to output layer\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","# Initializing  the model\n","model = SimpleNN(input_features=4, hidden_units=10, output_features=3)\n"],"metadata":{"id":"nxkqLUjxBLB5","executionInfo":{"status":"ok","timestamp":1729860396540,"user_tz":240,"elapsed":15,"user":{"displayName":"Kalyani Jaywant Khandait","userId":"07604933641220040068"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Setting loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","# Training loop\n","num_epochs = 1000\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","    outputs = model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 100 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xdh2LNkMBKy_","executionInfo":{"status":"ok","timestamp":1729860397774,"user_tz":240,"elapsed":1248,"user":{"displayName":"Kalyani Jaywant Khandait","userId":"07604933641220040068"}},"outputId":"0f8e29f0-6f37-41d2-da89-0cb91badb6f1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [100/1000], Loss: 0.0827\n","Epoch [200/1000], Loss: 0.0503\n","Epoch [300/1000], Loss: 0.0453\n","Epoch [400/1000], Loss: 0.0436\n","Epoch [500/1000], Loss: 0.0429\n","Epoch [600/1000], Loss: 0.0425\n","Epoch [700/1000], Loss: 0.0422\n","Epoch [800/1000], Loss: 0.0421\n","Epoch [900/1000], Loss: 0.0419\n","Epoch [1000/1000], Loss: 0.0418\n"]}]},{"cell_type":"code","source":["# Testing the model\n","model.eval()\n","with torch.no_grad():\n","    test_outputs = model(X_test_tensor)\n","    _, predicted = torch.max(test_outputs, 1)\n","    _, labels = torch.max(y_test_tensor, 1)\n","    accuracy = (predicted == labels).float().mean()*100\n","    print(f'Accuracy: {accuracy:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUA0HR6PBKE0","executionInfo":{"status":"ok","timestamp":1729860397775,"user_tz":240,"elapsed":19,"user":{"displayName":"Kalyani Jaywant Khandait","userId":"07604933641220040068"}},"outputId":"e62338b5-b4cd-47fc-c060-8c0f01d7f56d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 100.0000\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"t5jXmU0OCWHn","executionInfo":{"status":"ok","timestamp":1729860397775,"user_tz":240,"elapsed":13,"user":{"displayName":"Kalyani Jaywant Khandait","userId":"07604933641220040068"}}},"execution_count":5,"outputs":[]}]}